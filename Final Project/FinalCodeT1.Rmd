---
title: "Group 1 Final"
author: "Evelyn Campo, Xiao Qi, Nusrat Prithee, Roman Kosarzycki"
date: "April 27, 2022"
output:  
    rmdformats::readthedown:
      toc_float: true
      number_sections: true
      includes:
        before_body: header.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(scipen = 999, digits = 3, big.mark=",", warn = -1)
```

```{r basicfunct, include=FALSE}
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

```{r init, include=FALSE}
library(ezids)
library(ggplot2)
library(dplyr)
loadPkg("tidyr")
```

```{r}
# My functions

GeomSplitViolin <- ggproto("GeomSplitViolin", GeomViolin, draw_group = function(self, data, ..., draw_quantiles = NULL){
  data <- transform(data, xminv = x - violinwidth * (x - xmin), xmaxv = x + violinwidth * (xmax - x))
  grp <- data[1,'group']
  newdata <- plyr::arrange(transform(data, x = if(grp%%2==1) xminv else xmaxv), if(grp%%2==1) y else -y)
  newdata <- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ])
  newdata[c(1,nrow(newdata)-1,nrow(newdata)), 'x'] <- round(newdata[1, 'x']) 
  if (length(draw_quantiles) > 0 & !scales::zero_range(range(data$y))) {
    stopifnot(all(draw_quantiles >= 0), all(draw_quantiles <= 
                                              1))
    quantiles <- create_quantile_segment_frame(data, draw_quantiles)
    aesthetics <- data[rep(1, nrow(quantiles)), setdiff(names(data), c("x", "y")), drop = FALSE]
    aesthetics$alpha <- rep(1, nrow(quantiles))
    both <- cbind(quantiles, aesthetics)
    quantile_grob <- GeomPath$draw_panel(both, ...)
    ggplot2:::ggname("geom_split_violin", grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))
  }
  else {
    ggplot2:::ggname("geom_split_violin", GeomPolygon$draw_panel(newdata, ...))
  }
})

geom_split_violin <- function (mapping = NULL, data = NULL, stat = "ydensity", position = "identity", ..., draw_quantiles = NULL, trim = TRUE, scale = "area", na.rm = FALSE, show.legend = NA, inherit.aes = TRUE) {
  layer(data = data, mapping = mapping, stat = stat, geom = GeomSplitViolin, position = position, show.legend = show.legend, inherit.aes = inherit.aes, params = list(trim = trim, scale = scale, draw_quantiles = draw_quantiles, na.rm = na.rm, ...))
}

getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```

# Introduction
Heart disease is one of the most common diseases and a leading cause of death in the United States. This dataset takes data from the CDC for the year 2020 for people with and without heart disease. It includes health-related data including BMI, whether someone is a smoker, the amount of physical activity, age, race, and other variables. Our hope is that by studying how different health variables relate to instances of heart disease, we can determine if there are significant factors that can predict heart disease or are correlated with heart disease. In addition to this, the dataset includes a measure of mental health. We were interested in what factors can affect mental health. For instance, drinking, smoking, and physical activity were predicted to have some impact on overall mental health. Lastly, we want to look at the relation between BMI and physical activity. There have been some recent studies that BMI does not have any correlation to physical health, so weâ€™d like to use this dataset to explore that relation.

## Background



## Description of the Dataset

This data comes from a 2020 survey from the CDC on health status, used to study overall health and potential contributors to heart disease. The original dataset had 279 variables and over 400,000 rows, but the version which was uploaded to Kaggle contains 18 variables which could potentially influence heart disease and just over 320,000 complete rows, so there are no NA's and all 18 of the variables were taken into account in some way. The 18 variables consist of the following: HeartDisease, BMI, Smoking, AlcoholDrinking, Stroke, PhysicalHealth, MentalHealth, DiffWalking, Sex, AgeCategory, Race, Diabetic, PhysicalActivity, GenHealth, SleepTime, Asthma, KidneyDisease, SkinCancer. Most of these are straightforward variables that correspond with their name, but there are a few which require further explanation.

The people interviewed for this survey would answer "Yes" for Smoking if they have smoked at least 100 cigarettes in their entire lifetime and "Yes" to AlcoholDrinking if they are considered heavy drinkers (more than 14 drinks per week for men and 7 for women). PhysicalHealth and MentalHealth are numerical variables which give the number days in the past 30 days during which their physical or mental health, respectively, could be considered not good. That means that lower values correspond to less days of poor health. Recipients answered "Yes" to DiffWalking if they have any difficulty walking or climbing stairs. Diabetic is a four-level factor variable which records if they have ever had diabetes with the following responses: "No", "Borderline", "Yes (during pregnancy)", or "Yes". PhysicalActivity records whether the recipients reported any physical activity in the past 30 days outside of their regular job. The rest of the variables should be relatively self-explanatory given their names. 

# Understanding the Data

## Dataset Summary

Importing the dataset and original data structure:

```{r}
heartdata <- data.frame(read.csv("heart_2020_cleaned.csv"))
str(heartdata)
```

## Cleaning the Dataset

*All but five of the variables were set to factors. Most factor variable had 2 levels (yes or no questions), but some had up to six levels.

*In the variable Race, "American Indian/Alaskan Native" was redefined to "Native" in order to conserve space on plots and tables, but it should be noted that these two groups make up that level

*In the variable Diabetic, "No, borderline diabetes" was redefined to "Borderline" in order to conserve space. There is no information lost in doing this.

*An order to the factor variables Race, Diabetic, and GenHealth was established to keep the orders uniform across plots and tables. The order for Race is based on relative frequency (with "Other" being at the end) and the other two varriables were put in a logical order.

*The variable AgeCategory was replaced with Age so that it could be used as a numerical variable. A random value was chosen in the range given by AgeCategory, that value was set to Age, and unnecessary variables were deleted.

```{r}
heartdata$HeartDisease <- as.factor(heartdata$HeartDisease)
heartdata$Smoking <- as.factor(heartdata$Smoking)
heartdata$AlcoholDrinking <- as.factor(heartdata$AlcoholDrinking)
heartdata$Stroke <- as.factor(heartdata$Stroke)
heartdata$DiffWalking <- as.factor(heartdata$DiffWalking)
heartdata$Sex <- as.factor(heartdata$Sex)
heartdata$Race <- gsub("American Indian/Alaskan Native","Native",heartdata$Race)
heartdata$Race <- factor(heartdata$Race,levels=c("White","Hispanic","Black","Asian","Native","Other"))
heartdata$Diabetic <- gsub("No, borderline diabetes","Borderline",heartdata$Diabetic)
heartdata$Diabetic <- factor(heartdata$Diabetic,levels=c("No","Borderline","Yes (during pregnancy)","Yes"))
heartdata$PhysicalActivity <- as.factor(heartdata$PhysicalActivity)
heartdata$GenHealth <- factor(heartdata$GenHealth,levels=c("Poor","Fair","Good","Very good","Excellent"))
heartdata$Asthma <- as.factor(heartdata$Asthma)
heartdata$KidneyDisease <- as.factor(heartdata$KidneyDisease)
heartdata$SkinCancer <- as.factor(heartdata$SkinCancer)

heartdata$AgeCategory <- gsub(" or older","-84",as.character(heartdata$AgeCategory))
heartdata$HiAge <- as.numeric(substr(heartdata$AgeCategory,4,5))
heartdata$rand <- sample(0:4,size=nrow(heartdata),replace=T)
heartdata$Age <- with(heartdata,HiAge-rand)

heartdata <- subset(heartdata,select=-c(AgeCategory,HiAge,rand))

posdis <- subset(heartdata,HeartDisease=="Yes")
negdis <- subset(heartdata,HeartDisease=="No")

str(heartdata)
```

# Exploratory Data Analysis

## Understanding the Data

```{r}
# Pie graphs

hear<-table(heartdata$HeartDisease)
pie(hear,col = rainbow(length(hear)),main="Heart Disease?")

smok<-table(heartdata$Smoking)
pie(smok,col = rainbow(length(smok)),main="Smoker?")

drin<-table(heartdata$AlcoholDrinking)
pie(drin,col = rainbow(length(drin)),main="Heavy Drinker?")

race<-table(heartdata$Race)
pie(race,col = rainbow(length(race)),main="Race?")

sexx<-table(heartdata$Sex)
pie(sexx,col = rainbow(length(sexx)),main="Sex?")
```

These pie charts give the relative frequency of a few key factor variables. The show that a majority of people do not have heart disease, have not smoked, are not heavy drinkers, are white, and are female.

```{r}
# Histograms of numerical variables

ggplot(data=heartdata, aes(x=BMI))+geom_histogram(bins=50)+xlim(0,75)+ggtitle("Distribution of BMI")+geom_vline(xintercept = mean(heartdata$BMI,na.rm = TRUE), color = "red", size=1.5)+geom_vline(xintercept = median(heartdata$BMI,na.rm = TRUE), color = "blue", size=1.5)+geom_vline(xintercept = getmode(heartdata$BMI), color = "orange", size=1.5)

ggplot(data=heartdata, aes(x=PhysicalHealth))+geom_histogram(bins=30)+ggtitle("Distribution of Days of Poor Physical Health")
ggplot(data=heartdata, aes(x=MentalHealth))+geom_histogram(bins=30)+ggtitle("Distribution of Days of Poor Mental Health")

ggplot(data=heartdata, aes(x=SleepTime))+geom_histogram(bins=12)+xlim(2,13)+ggtitle("Distribution of Sleep Time")+geom_vline(xintercept = mean(heartdata$SleepTime,na.rm = TRUE), color = "red", size=1.5)+geom_vline(xintercept = median(heartdata$SleepTime,na.rm = TRUE), color = "blue", size=1.5)+geom_vline(xintercept = getmode(heartdata$SleepTime), color = "orange", size=1.5)

ggplot(data=heartdata, aes(x=Age))+geom_histogram(bins=65)+ggtitle("Distribution of Ages")+geom_vline(xintercept = mean(heartdata$Age,na.rm = TRUE), color = "red", size=1.5)+geom_vline(xintercept = median(heartdata$Age,na.rm = TRUE), color = "blue", size=1.5)+geom_vline(xintercept = getmode(heartdata$Age), color = "orange", size=1.5)
```

These histograms give a brief look at the numerical variables. BMI has an average value of 28.3 with a right skew. A majority of people reported 0 days of poor physical and mental health over the past 30 days. The average for sleep time and age is 7.1 hours and 54.6 years, respectively. 

## Smart Question: What variables affect instances of heart disease?

```{r}
# Comparison of factors

hea<-table(heartdata$HeartDisease)
#hea
#No heart disease
#hea[1]/(hea[1]+hea[2])
#Heart disease
#hea[2]/(hea[1]+hea[2])
xkabledply(hea, title = paste("Instances of Heart Disease:" ) )

smo<-table(heartdata$HeartDisease,heartdata$Smoking)
#smo
#No smoking, no heart disease
#smo[1]
#smo[1]/(smo[1]+smo[2])
#No smoking, heart disease
#smo[2]
#smo[2]/(smo[1]+smo[2])
#Smoking, no heart disease
#smo[3]
#smo[3]/(smo[3]+smo[4])
#Smoking, heart disease
#smo[4]
#smo[4]/(smo[3]+smo[4])
xkabledply(smo, title = paste("Heart Disease vs. Smoking:" ) )

dri<-table(heartdata$HeartDisease,heartdata$AlcoholDrinking)
#dri
#No drinking, no heart disease
#dri[1]
#dri[1]/(dri[1]+dri[2])
#No drinking, heart disease
#dri[2]
#dri[2]/(dri[1]+dri[2])
#Drinking, no heart disease
#dri[3]
#dri[3]/(dri[3]+dri[4])
#Drinking, heart disease
#dri[4]
#dri[4]/(dri[3]+dri[4])
xkabledply(dri, title = paste("Heart Disease vs. Drinking:" ) )

dia<-table(heartdata$HeartDisease,heartdata$Diabetic)
#dia
xkabledply(dia, title = paste("Heart Disease vs. Diabetes:" ) )

stro<-table(heartdata$HeartDisease,heartdata$Stroke)
#stro
xkabledply(stro, title = paste("Heart Disease vs. Stroke:" ) )

wal<-table(heartdata$HeartDisease,heartdata$DiffWalking)
#wal
xkabledply(wal, title = paste("Heart Disease vs. Difficulty Walking:" ) )

phy<-table(heartdata$HeartDisease,heartdata$PhysicalActivity)
#phy
xkabledply(phy, title = paste("Heart Disease vs. Physical Activity:" ) )

ast<-table(heartdata$HeartDisease,heartdata$Asthma)
#ast
xkabledply(ast, title = paste("Heart Disease vs. Asthma:" ) )

kid<-table(heartdata$HeartDisease,heartdata$KidneyDisease)
#kid
xkabledply(kid, title = paste("Heart Disease vs. Kidney Disease:" ) )

ski<-table(heartdata$HeartDisease,heartdata$SkinCancer)
#ski
xkabledply(ski, title = paste("Heart Disease vs. Skin Cancer:" ) )
```

These are various tables which compare factor variables with instances of heart disease. To summarize briefly, there were more instances of heart disease with people who had smoked, were heavy drinkers, had a stroke, had difficulty walking, were not physically active, had asthma, had kidney disease, had diabetes, and had skin cancer. 

```{r}
# Heart disease and BMI

ggplot(heartdata, aes(x=HeartDisease, y=BMI, fill=HeartDisease)) + geom_boxplot(outlier.shape = NA)+ggtitle("Heart Disease by BMI")+ylim(15,45)
```

This boxplot looks at the distribution of BMI values for people with and without heart disease. The median BMI was 27.3 for people without heart disease and 28.3 for people with heart disease.

```{r}
# Heart disease and Age

ggplot(heartdata, aes(x=HeartDisease, y=Age, fill=HeartDisease)) + geom_boxplot(outlier.shape = NA)+ggtitle("Heart Disease by Age")+coord_flip()

agelist <- sort(unique(heartdata$Age))
Age <- c()
PositiveMale <- c()
PositiveFemale <- c()
TotalMale <- c()
TotalFemale <- c()
Male <- c()
Female <- c()
Sex <- c()
Positive <- c()
Total <- c()

for (x in 1:length(agelist)){
  Age <- c(Age,agelist[x])
  PositiveMale <- c(PositiveMale, nrow(subset(heartdata,Age==agelist[x] & HeartDisease=="Yes" & Sex=="Male")))
  PositiveFemale <- c(PositiveFemale, nrow(subset(heartdata,Age==agelist[x] & HeartDisease=="Yes" & Sex=="Female")))
  TotalMale <- c(TotalMale, nrow(subset(heartdata,Age==agelist[x] & Sex=="Male")))
  TotalFemale <- c(TotalFemale, nrow(subset(heartdata,Age==agelist[x] & Sex=="Female")))
  Male <- c(Male,"Male")
  Female <- c(Female, "Female")
}

Sex <- c(Male,Female)
Positive <- c(PositiveMale,PositiveFemale)
Total <- c(TotalMale,TotalFemale)
agedata <- data.frame(Age, Positive, Total, Sex)
agedata['Percentage'] <- 100*Positive/Total
agedata$Sex <- factor(agedata$Sex,levels=c("Male","Female"))

ggplot(agedata, aes(x=Age,y=Percentage,fill=Sex)) + geom_area(position="identity") +scale_fill_manual(values=c("blue","magenta")) + ggtitle("Heart Disease by Age and Sex")
```

These two plots look at instances of heart disease compared to both age and sex. The median age of people with heart disease was 70 years versus 55 years for people without. The area plot demonstrates an increase in the percentage of people with heart disease as their age increases and also shows that men are more likely to have heart disease than women.

```{r}
# Heart disease versus gen health

ggplot(posdis, aes(x=GenHealth,fill=GenHealth)) + geom_bar()+ggtitle("General Health for People With Heart Disease")

ggplot(negdis, aes(x=GenHealth,fill=GenHealth)) + geom_bar()+ggtitle("General Health for People Without Heart Disease")

ggplot(heartdata,aes(GenHealth,Age,fill=HeartDisease))+geom_split_violin()+ggtitle("Age and General Health for People With and Without Heart Disease")
```

These two bar graphs and split violin plot look at general health for people with and without heart disease. The most common response was "Good" health for people with heart disease and "Very good" for people without heart disease. The violin plot confirms the relationship between heart disease and age while showing the distribution of people in each health category versus age in each case.

```{r}
# Heart disease vs. race and age

ggplot(heartdata,aes(Race,Age,fill=HeartDisease))+geom_split_violin()+ggtitle("Age and Race for People With and Without Heart Disease")

rac <- table(heartdata$HeartDisease,heartdata$Race)
Race <- c("White","Hispanic","Black","Asian","Native","Other")
Percentage <- c(100*rac[2]/(rac[1]+rac[2]),100*rac[4]/(rac[3]+rac[4]),100*rac[6]/(rac[5]+rac[6]),100*rac[8]/(rac[7]+rac[8]),100*rac[10]/(rac[11]+rac[10]),100*rac[12]/(rac[11]+rac[12]))
racedata <- data.frame(Race,Percentage)
racedata$Race <- factor(racedata$Race,levels=c("White","Hispanic","Black","Asian","Native","Other"))

ggplot(racedata,aes(x=Race,y=Percentage,fill=Race))+geom_bar(stat="identity")+ggtitle("Percentage of People With Heart Disease")
```

This split violin plot and accompanying bar graph look at race and age versus heart disease. The violin plot shows the unexpected result that non-white people report having heart disease at younger ages when compared to white people. The bar graph shows that a higher percentage of white people get heart disease (9.2%) and a lower percentage of Asian people (3.3%) have heart disease, with the other races falling somewhere between those two values.

## Smart Question: What variables affect mental health?

```{r}
# Mental health

heartdata2 <- heartdata
heartdata2 <- heartdata2[heartdata2$MentalHealth != 0,]
heartdata2$SleepTime <-ifelse(heartdata2$SleepTime<7,"Too little",ifelse(heartdata2$SleepTime>9,"Too much","Recommended"))
heartdata2$Sleep <- factor(heartdata2$SleepTime,levels=c("Too little","Recommended","Too much"))

ggplot(heartdata2, aes(x=Smoking, y=MentalHealth, fill=Smoking)) + geom_boxplot(outlier.shape = NA)+ggtitle("Mental Health for Smokers and Non-Smokers")

ggplot(heartdata2, aes(x=AlcoholDrinking, y=MentalHealth, fill=AlcoholDrinking)) + geom_boxplot(outlier.shape = NA)+ggtitle("Mental Health for Drinkers and Non-Drinkers")

ggplot(heartdata2, aes(x=PhysicalActivity, y=MentalHealth, fill=PhysicalActivity)) + geom_boxplot(outlier.shape = NA)+ggtitle("Mental Health versus Physical Activity")

ggplot(heartdata2, aes(x=Sleep, y=MentalHealth, fill=Sleep)) + geom_boxplot(outlier.shape = NA)+ggtitle("Mental Health versus Sleep")
```

These four boxplots look at what variables affect mental health. It should be noted that since over 60% of total recipients reported 0 days of poor mental health, those instances were omitted, so these plots look at people who have reported at least 1 day of poor mental health. They show that people have less poor mental health days when they don't smoke, aren't heavy drinkers, are physically active, and get the recommended amount of sleep (7 to 9 hours per night).

## Smart Question: Does BMI have any effect on physical health?

```{r}
# BMI and health

ggplot(heartdata, aes(x=GenHealth, y=BMI, fill=GenHealth)) + geom_boxplot(outlier.shape = NA)+ggtitle("General Health by BMI")+ylim(15,45)
```

This boxplot compares general health categories to recorded BMI. Those who reported "Excellent" health had the lowest median BMI (25.4) and those who reported "Fair" health had the highest median BMI (29.4).


```{r include=FALSE}

heartdata <- data.frame(read.csv("heart_2020_cleaned.csv"))

n=10
#heartdata <- heartdata[seq(1,nrow(heartdata),n),]

heartdata$HeartDisease <- as.factor(heartdata$HeartDisease)
heartdata$Smoking <- as.factor(heartdata$Smoking)
heartdata$AlcoholDrinking <- as.factor(heartdata$AlcoholDrinking)
heartdata$Stroke <- as.factor(heartdata$Stroke)
heartdata$DiffWalking <- as.factor(heartdata$DiffWalking)
heartdata$Sex <- as.factor(heartdata$Sex)
heartdata$Race <- as.factor(heartdata$Race)
heartdata$Diabetic <- as.factor(heartdata$Diabetic)
heartdata$PhysicalActivity <- as.factor(heartdata$PhysicalActivity)
heartdata$GenHealth <- as.factor(heartdata$GenHealth)
heartdata$Asthma <- as.factor(heartdata$Asthma)
heartdata$KidneyDisease <- as.factor(heartdata$KidneyDisease)
heartdata$SkinCancer <- as.factor(heartdata$SkinCancer)

heartdata$AgeCategory <- gsub(" or older","-4",as.character(heartdata$AgeCategory))
heartdata$LoAge <- as.numeric(substr(heartdata$AgeCategory,1,2))
heartdata$rand <- sample(0:4,size=nrow(heartdata),replace=T)
heartdata$Age <- with(heartdata,LoAge+rand)
heartdata <- subset(heartdata,select=-c(AgeCategory,LoAge,rand))

str(heartdata)

```
# Testing

## Chi-Square Test

The Chi-square test of independence is a statistical hypothesis test used to determine whether two variables are likely to be related or not. We conduct couple of chi-square test to check the variables are independent or not.

### Is heart disease data related to gender?

We want to check the Heart Disease variable is related to the gender variable. We conduct a chi-square test to check whether Heart Disease and Sex are independent. 
H0: Heart Disease and Sex are independent from each other. 
H1: Heart Disease and Sex are not independent from each other.

```{r, results="markup"}
sextable= table(heartdata$HeartDisease,heartdata$Sex)

ezids::xkabledply(sextable, title="Contingency table for Heart Disease  vs Gender ")
chitest_sex = chisq.test(sextable)
chitest_sex

```
A contingency table is created with the two variables to do the chi-square test.Contingency table shows how many women and men are suffering heart disease, how many women and men are not suffering heart disease. According to table men are more suffering heart disease compare to women. Chi-square has found weather the variables on the data set are realted or not. Here,From the chi-square test P value is 2.2e-16.P value less than 0.05. That reject null Hypothesis. That's mean heart disease data and gender are related to each other.

### Does the data support that race very much affects heart disease?

We want to check the Heart Disease variable is related to the Race variable. We conduct a another chi-square test to check whether Heart Disease and Race are independent. 
H0: Heart Disease and race are independent from each other. 
H1: Heart Disease and race are not independent from each other.

```{r, results="markup"}
racetable = xtabs(~ Race+HeartDisease, data =heartdata )
racetable
chitest_race = chisq.test(racetable)
chitest_race
```
Table shows how many people are suffering heart disease and not suffering heart disease according to race. According to table White are more suffering heart disease compare to other race. Chi-square has found weather the variables on the data set are related or not. Here,From the chi-square test P value is 2.2e-16. P value less than 0.05. That reject null Hypothesis. That's mean data supports race has effect on heart disease.

### Does the data support that Heart Disease effect on Gen Health?

The last chi-square test is to check the data heart disease is independent to general health.
H0: Heart Disease and Gen Health are independent from each other. 
H1: Heart Disease and Gen Health are not independent from each other.
```{r, results="markup"}
gentable= table(heartdata$HeartDisease,heartdata$GenHealth)
ezids::xkabledply(gentable, title="Contingency table for Heart Disease  vs Gen Health ")
chitest_gen = chisq.test(gentable)
chitest_gen
```
The contingency table shows the number of active heart disease patient are heaving general health condition in five categories. Chi-square has found weather the variables on the data set are related or not. Here,From the chi-square test P value is 2.2e-16. Here, P value less than 0.05. That reject null Hypothesis. That's mean data support that Heat Disease effect on Gen Health

## T-test

### What is the average age people are suffering from heart disease?

On our data set Heart Disease is factor variable and Age is numeric variable. To find the average age of people having heart disease T-test is chosen for. A t-test is a  test compares the mean of your sample data to a known value. By conducting t-test, average  value (mean value) of people's age having heart disease has been found. Mean values from t-test are analyzed to find the  average age of people are suffering heart diseases. 
```{r, results="markup"}
 heart_disease_on=subset(heartdata,HeartDisease=="Yes")
ttest_age <- t.test(heart_disease_on$Age)
ttest_age
```
Here, we have subset the dataset to separate the values where HeartDisease factor variable is Yes. Then conducting the t-test to know the average age.The result shows that, the values Average of heaving heart disease is 68.

## Test For Association

Correlation test is used to evaluate the association between two or more variables.
Pearson's  can range from âˆ’1 to 1. An r of âˆ’1 indicates a perfect negative linear relationship between variables, an r of 0 indicates no linear relationship between variables, and an r of 1 indicates a perfect positive linear relationship between variables.

### What variables affect mental health physical health? In particular, does alcohol drinking, smoking

To know the effect of smoking and drinking on mental and physical health Pearson's method of cor test is used.
```{r results='markup'}
menhealth_smoke<-cor.test(heartdata$MentalHealth,as.numeric(heartdata$Smoking), method="pearson")
menhealth_smoke
menhealth_drinking<-cor.test(heartdata$MentalHealth,as.numeric(heartdata$AlcoholDrinking), method="pearson")
menhealth_drinking
```  
Smoking and drinking variables do not have enough strong correlation with mental health.Here, Cor value of smoking is 0.08515729, drinking alcohol is 0.05128197.Smoking has more stronger correlation than drinking alcohol with mental health.
```{r results='markup'}
phyhealth_smoke<-cor.test(heartdata$PhysicalHealth,as.numeric(heartdata$Smoking), method="pearson")
phyhealth_smoke
phyhealth_drinking<-cor.test(heartdata$PhysicalHealth,as.numeric(heartdata$AlcoholDrinking), method="pearson")
phyhealth_drinking
```
Smoking and drinking variables do not have enough strong correlation with physical health.Here, Cor value of smoking is 0.1153524, drinking alcohol is -0.01725429.Smoking has more stronger correlation than drinking alcohol with physical health where drinking alcohol is negatively correlated.

# Model building
## SMART Question

*What variables affect instances of heart disease?*

Our goal is to find out the people who are likely to have heart disease in the future, so we can take some actions like a more detailed physical examination before the conditions become worse.

## Pre-processing amd balancing the data

The first step is to do some pre-processing work.

First, because I will use *bestglm::bestglm()*, a feature selection method, to decide which variables are essential and which are not, I must clean the dataset with the target variable renamed y and all other unused variables removed from the dataset. So I put the HeartDisease column at the end of the dataset and renamed it y.

Second, considering that there are too few rows with the value "Yes (during pregnancy)" in the Diabetic variable, I combine the value "Yes (during pregnancy)" and "Yes" together in the Diabetic variable.

These are the two pre-processing steps in the model building part.

```{r include=FALSE}
heartdata2 <- data.frame(read.csv("heart_2020_cleaned.csv"))
heartdata2$Smoking <- as.factor(heartdata2$Smoking)
heartdata2$AlcoholDrinking <- as.factor(heartdata2$AlcoholDrinking)
heartdata2$Stroke <- as.factor(heartdata2$Stroke)
heartdata2$DiffWalking <- as.factor(heartdata2$DiffWalking)
heartdata2$Sex <- as.factor(heartdata2$Sex)
heartdata2$Race <- as.factor(heartdata2$Race)
heartdata2$PhysicalActivity <- as.factor(heartdata2$PhysicalActivity)
heartdata2[heartdata2$GenHealth == 'Poor', "GenHealth"] <- 0
heartdata2[heartdata2$GenHealth == 'Fair', "GenHealth"] <- 1
heartdata2[heartdata2$GenHealth == 'Good', "GenHealth"] <- 2
heartdata2[heartdata2$GenHealth == 'Very good', "GenHealth"] <- 3
heartdata2[heartdata2$GenHealth == 'Excellent', "GenHealth"] <- 4
#heartdata2$GenHealth <- as.factor(heartdata2$GenHealth)
heartdata2$GenHealth <- as.numeric(heartdata2$GenHealth)
heartdata2$Asthma <- as.factor(heartdata2$Asthma)
heartdata2$KidneyDisease <- as.factor(heartdata2$KidneyDisease)
heartdata2$SkinCancer <- as.factor(heartdata2$SkinCancer)
heartdata2$AgeCategory <- gsub(" or older","-4",as.character(heartdata2$AgeCategory))
heartdata2$LoAge <- as.numeric(substr(heartdata2$AgeCategory,1,2))
heartdata2$rand <- sample(0:4,size=nrow(heartdata2),replace=T)
heartdata2$Age <- with(heartdata2,LoAge+rand)
heartdata2 <- subset(heartdata2,select=-c(AgeCategory,LoAge,rand))
```

```{r}
heartdata2[heartdata2$Diabetic == 'Yes (during pregnancy)', "Diabetic"] <- 'Yes'
heartdata2$Diabetic <- as.factor(heartdata2$Diabetic)
heartdata2$y <- as.factor(heartdata2$HeartDisease)
heartdata2 = subset(heartdata2, select = -c(HeartDisease))

# str(heartdata2)
```

After preprocessing, I need to balance the data. Let us look at the proportion of heart disease data before we continue our research.

```{r results='markup'}
table( heartdata2$y )
```

We can find that the dataset is very unbalanced. Only 8.6% of the dataset has the value of 1 for y (HeartDisease). Considering that the dataset is large, I use undersampling methods to balance the dataset. After the balancing work, the value zero and value one of y are the same. And there is a reference for different balancing methods:  https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/

```{r}
loadPkg("ROSE")
data_balanced_under <- ovun.sample(y ~ ., data = heartdata2, method = "under", N = 27373*2, seed = 1)$data
rm(heartdata2)
unloadPkg("ROSE") 
```

We can find that the data is really balanced now.
```{r results='markup'}
table( data_balanced_under$y )
```

Before we begin the logistic regression model, let us look at the structure of the dataset now.
```{r results='markup'}
str(data_balanced_under)
```

## logistic regression model

I split the dataset into two parts to train and evaluate the model later. 80% of the dataset will be used to train the model, and the rest 20% will be used to test the model's accuracy. I will use *createDataPartition* in the *caret* library to split the dataset.
```{r}
loadPkg("caret")
set.seed(4321)
test <- createDataPartition( data_balanced_under$y, p = .2, list = FALSE )
data_train <- data_balanced_under[ -test, ]
data_test  <- data_balanced_under[ test, ]
unloadPkg("caret") 
```

After I split the data, the training dataset is used to build the model. First, I use all variables as independent variables and make a model as below.
```{r results='markup'}
model_glm <- glm( y ~ ., data = data_train, family = binomial(logit) )
summary_glm <- summary(model_glm)
summary_glm
```

We can find from the model that the p-values of Race and PhysicalActivity are more significant than 0.05, which means these two variables are insignificant. So just drop these two variables and make the second logistic regression model again.

```{r results='markup'}
model2_glm <- glm( y ~ . - Race - PhysicalActivity, data = data_train, family = binomial(logit) )
summary2_glm <- summary(model2_glm)
summary2_glm
```


We will quickly check two things for this model. The first is the p-values. P-values below .05 indicate significance, which means the coefficient or so-called parameters that our model estimates are reliable. And second, the pseudo R square. This value ranging from 0 to 1, indicates how much variance our model explains.

We can find that all the p-values of the model indicate significance, meaning that our model is a legitimate one. An R square of 0.29 tells that 29 percent of the variance is explained.

```{r}
list( summary2_glm$coefficient, 
      round( 1 - ( summary2_glm$deviance / summary2_glm$null.deviance ), 2 ) )
```

After we finish this, we can have a look at the Variance Inflation Factor (vif).

* When 1 < vif < 5, it means the variables are mildly correlated. It's acceptable.
* When 5 < vif < 10, it means moderately correlated, and it also can be acceptable.
* When vif > 10, it's not acceptable.

```{r results='markup'}
vif_md2 = faraway::vif(model2_glm)
vif_md2
```

We can find that some vif values are larger than 10, which means these variables are highly correlated and not acceptable. So I tried to drop one variable at a time. In the meantime, look at the p-value to ensure that the variables are significant. In the end, I got the model below:

```{r results='markup'}
model3_glm <- glm( y ~ . - Race - PhysicalActivity - Age - Asthma - PhysicalHealth, data = data_train, family = binomial(logit) )
summary3_glm <- summary(model3_glm)
summary3_glm
```

```{r results='markup'}
vif_md3 = faraway::vif(model3_glm)
vif_md3
```

And also check the vif. We can find that all the vif values are all below 10.


## Feature selection
In this part, I want to use feature selection to find out the most suitable variables from our current model. Unfortunately, the training dataset has more than 40,000 rows, which is significant and takes much time to run. So I changed the test dataset to make the feature selection. The test dataset has the same data structure but fewer rows.

```{r}
data_feature_selection = subset(data_test, select = -c(Race, PhysicalActivity, PhysicalHealth, Age, Asthma))
str(data_feature_selection)
```

Although lacking intuitive visual presentation of results, *bestglm::bestglm()* can handle logistic regression. So I use it to do the feature selection.

```{r results='markup'}
loadPkg("bestglm")
res.bestglm <- bestglm(Xy = data_feature_selection, family = binomial,
            IC = "AIC",                 # Information criteria for
            method = "backward")
summary(res.bestglm)
res.bestglm$BestModels
summary(res.bestglm$BestModels)
unloadPkg("bestglm") 
unloadPkg("leaps") 
```

Through the feature selection, we can find that the best model has all these 13 variables, and its CIA (Akaike Information Criterion) is 12062, which is the lowest among these models. It's the model which we built before.


## Model Evaluation

In this part, I will use AUC and confusion matrix to evalute the model.

### ROC and AUC

Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC) measures the true positive rate (or sensitivity) against the false positive rate (or specificity). The area-under-curve is always between 0.5 and 1. Values higher than 0.8 is considered good model fit.  
```{r roc_auc}
loadPkg("pROC") # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
prob=predict(model3_glm, type = "response" )
data_train$prob=prob
h <- roc(y~prob, data=data_train)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)
# unloadPkg("pROC")
```

The AUC of the model is 0.795, which is a little bit lower than 0.8. Because our model looks suitable and we have all the needed features, I suppose that the data causes the lower AUC value. 


#### Confusion matrix 

We can have a look of the Confusion matrix.

```{r confusionMatrix, results='markup'}
# install.packages("regclass")
library("regclass")
# confusion_matrix(admitLogit)
xkabledply( confusion_matrix(model3_glm), title = "Confusion matrix from Logit Model" )
unloadPkg("regclass")
```

We can find from the confusion matrix that Precision is 14941/(5252+14941) = 0.74, which means the valid of the result is 74%. And the recall is 14941/(6957+14941) = 0.68, which means how complete the results are 68%.

In our model, actually, I think the recall is more important, because FN means heart disease patients who are missed by our model, which can cause a harmful result.


```{r results='markup'}
loadPkg("InformationValue")
predicted = predict(model3_glm, data_test, type = "response")

confusionMatrix(data_test$y, predicted)
unloadPkg("InformationValue")
```

Then we can use the test dataset to checkout whether the model is good to use. So I used the data_test to make a prediction and calculate the confusion matrix by the test dataset. The Precision is 3722/(1255+3722) = 0.75 and the recall is 3722/(1753+3722) = 0.68.

The Precision value and recall value of the test dataset is similiar to the train dataset, which means our model is reliable to predict the heart disease.


## Interpretation and Reporting

Weâ€™ll return to our logistic regression model for a minute, and look at the estimated parameters (coefficients). Since the modelâ€™s parameter the recorded in logit format, I transformed it into odds ratio so that itâ€™ll be easier to interpret. After transforming, I sorted the variables by the coefficient values.

```{r results='markup'}
loadPkg("broom")

coefficient <- tidy(model3_glm)[ , c( "term", "estimate", "statistic" ) ]

# transfrom the coefficient to be in probability format 
coefficient$estimate <- exp( coefficient$estimate )
coefficient[sort(abs(coefficient$estimate),decreasing=T,index.return=T)[[2]],]

unloadPkg("broom")
```

We can find from the table that other diseases (stroke, kidney disease, diabetic, SkinCancer), general health conditions, sex, DiffWalking (serious difficulty walking or climbing stairs), and smoking habit all largely influence the possibility of heart disease. It's a little weird that drinking alcohol will reduce the possibility of heart disease. As we always think, drinking is not a good habit, maybe the data also includes people who drink some little wine.


